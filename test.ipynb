{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ca8d5d",
   "metadata": {},
   "source": [
    "## Test I/O with networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89210b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 NetworkX 创建的图:\n",
      "节点数: 34\n",
      "边数: 156\n",
      "邻接矩阵 (前5x5):\n",
      "[[0. 4. 5. ... 2. 0. 0.]\n",
      " [4. 0. 6. ... 0. 0. 0.]\n",
      " [5. 6. 0. ... 0. 2. 0.]\n",
      " ...\n",
      " [2. 0. 0. ... 0. 4. 4.]\n",
      " [0. 0. 2. ... 4. 0. 5.]\n",
      " [0. 0. 0. ... 4. 5. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from graphs import from_networkx, Graph\n",
    "\n",
    "# 从 networkx 创建\n",
    "nx_g = nx.karate_club_graph()\n",
    "jax_g = from_networkx(nx_g)\n",
    "\n",
    "print(\"从 NetworkX 创建的图:\")\n",
    "print(f\"节点数: {jax_g.n_nodes}\")\n",
    "print(f\"边数: {jax_g.n_edges}\")\n",
    "print(\"邻接矩阵 (前5x5):\")\n",
    "# 修改: 调用 to_adjacency_matrix() 方法\n",
    "print(jax_g.to_adjacency_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d97a7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makotoxu/Documents/Coding/JAX/graph-jax/graphs/io.py:63: UserWarning: 字符串特征 'club' 被自动编码为整数: {'Mr. Hi': 0, 'Officer': 1}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from graphs import from_networkx\n",
    "\n",
    "nx_g = nx.karate_club_graph()\n",
    "# 显式指定 'club' 作为特征键\n",
    "jax_g = from_networkx(nx_g, node_feature_key='club') \n",
    "\n",
    "print(jax_g.node_features.T) # 打印特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64c43d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 有向图转换验证 ---\n",
      "节点和边的数量一致。\n",
      "邻接矩阵一致。\n",
      "节点特征一致。\n",
      "边的方向和权重一致。\n",
      "\n",
      "补充测试完成，所有断言均通过。\n"
     ]
    }
   ],
   "source": [
    "# --- 补充测试：有向图和带权重的边 ---\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from graphs import from_networkx, to_networkx\n",
    "\n",
    "# 1. 创建一个复杂的有向、带权重的图\n",
    "nx_g_directed = nx.DiGraph()\n",
    "nx_g_directed.add_weighted_edges_from([\n",
    "    (0, 1, 0.5), \n",
    "    (1, 2, 1.5), \n",
    "    (2, 0, 2.5),\n",
    "    (2, 1, 3.0) # 反向边\n",
    "])\n",
    "# 添加一个孤立节点\n",
    "nx_g_directed.add_node(3) \n",
    "# 为节点添加特征\n",
    "features = {0: 10, 1: 20, 2: 30, 3: 40}\n",
    "nx.set_node_attributes(nx_g_directed, features, 'value')\n",
    "\n",
    "# 2. 转换到 JAX 图再转换回来\n",
    "jax_g_directed = from_networkx(nx_g_directed, node_feature_key='value')\n",
    "nx_g_reverted_directed = to_networkx(jax_g_directed, node_feature_key='value', create_using=nx.DiGraph)\n",
    "\n",
    "# --- 验证 ---\n",
    "print(\"--- 有向图转换验证 ---\")\n",
    "\n",
    "# 验证节点和边的数量\n",
    "assert nx_g_directed.number_of_nodes() == nx_g_reverted_directed.number_of_nodes()\n",
    "assert nx_g_directed.number_of_edges() == nx_g_reverted_directed.number_of_edges()\n",
    "print(\"节点和边的数量一致。\")\n",
    "\n",
    "# 验证邻接矩阵\n",
    "adj_original = nx.to_numpy_array(nx_g_directed)\n",
    "# 修改: 调用 to_adjacency_matrix() 方法\n",
    "is_adj_same = np.allclose(jax_g_directed.to_adjacency_matrix(), adj_original)\n",
    "assert is_adj_same\n",
    "print(\"邻接矩阵一致。\")\n",
    "\n",
    "# 验证节点特征\n",
    "reverted_features_raw = nx.get_node_attributes(nx_g_reverted_directed, 'value')\n",
    "reverted_features = np.array([reverted_features_raw[n] for n in sorted(reverted_features_raw.keys())])\n",
    "assert np.array_equal(jax_g_directed.node_features.flatten(), reverted_features)\n",
    "print(\"节点特征一致。\")\n",
    "\n",
    "# 验证边的权重和方向\n",
    "original_edges = set((u, v, d.get('weight', 1.0)) for u, v, d in nx_g_directed.edges(data=True))\n",
    "reverted_edges = set((u, v, d.get('weight', 1.0)) for u, v, d in nx_g_reverted_directed.edges(data=True))\n",
    "assert original_edges == reverted_edges\n",
    "print(\"边的方向和权重一致。\")\n",
    "\n",
    "print(\"\\n补充测试完成，所有断言均通过。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902a57c",
   "metadata": {},
   "source": [
    "## Test I/O with CSV & Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c43e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- JSON 读写测试 ---\n",
      "JSON 读写验证成功。文件已保存到: /Users/makotoxu/Documents/Coding/JAX/graph-jax/test_graph.json\n",
      "\n",
      "--- CSV 读写测试 ---\n",
      "CSV 读写验证成功。文件已保存到: /Users/makotoxu/Documents/Coding/JAX/graph-jax/test_graph.csv\n",
      "\n",
      "JSON 和 CSV 读写测试完成。\n"
     ]
    }
   ],
   "source": [
    "# --- JSON 和 CSV 读写测试 ---\n",
    "import os\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from graphs import Graph, to_json, from_json, to_csv, from_csv\n",
    "\n",
    "# 1. 修改: 创建一个用于测试的稀疏 JAX 图\n",
    "senders = jnp.array([0, 1, 1, 2])\n",
    "receivers = jnp.array([1, 0, 2, 1])\n",
    "weights = jnp.array([1.5, 1.5, 2.0, 2.0])\n",
    "test_features = jnp.array([\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "    [1.0, 1.0],\n",
    "])\n",
    "# 修改: 使用新的稀疏构造函数\n",
    "jax_g_test = Graph(\n",
    "    senders=senders, \n",
    "    receivers=receivers, \n",
    "    edge_weights=weights,\n",
    "    n_nodes=3, \n",
    "    n_edges=len(senders),\n",
    "    node_features=test_features\n",
    ")\n",
    "\n",
    "# 定义文件名\n",
    "json_path = \"test_graph.json\"\n",
    "csv_path = \"test_graph.csv\"\n",
    "\n",
    "# --- JSON 往返测试 ---\n",
    "print(\"--- JSON 读写测试 ---\")\n",
    "to_json(jax_g_test, json_path)\n",
    "# 修改: from_json 不再需要 directed 参数\n",
    "reloaded_g_json = from_json(json_path)\n",
    "\n",
    "# 验证 JSON\n",
    "assert jax_g_test.n_nodes == reloaded_g_json.n_nodes\n",
    "# 修改: 调用 to_adjacency_matrix() 方法\n",
    "assert np.allclose(jax_g_test.to_adjacency_matrix(), reloaded_g_json.to_adjacency_matrix())\n",
    "assert np.allclose(jax_g_test.node_features, reloaded_g_json.node_features)\n",
    "print(f\"JSON 读写验证成功。文件已保存到: {os.path.abspath(json_path)}\")\n",
    "# os.remove(json_path)\n",
    "\n",
    "# --- CSV 往返测试 ---\n",
    "print(\"\\n--- CSV 读写测试 ---\")\n",
    "to_csv(jax_g_test, csv_path)\n",
    "# 修改: from_csv 不再需要 directed 参数\n",
    "reloaded_g_csv = from_csv(csv_path)\n",
    "\n",
    "# 验证 CSV\n",
    "assert jax_g_test.n_nodes == reloaded_g_csv.n_nodes\n",
    "# 修改: 调用 to_adjacency_matrix() 方法\n",
    "assert np.allclose(jax_g_test.to_adjacency_matrix(), reloaded_g_csv.to_adjacency_matrix())\n",
    "print(f\"CSV 读写验证成功。文件已保存到: {os.path.abspath(csv_path)}\")\n",
    "# os.remove(csv_path)\n",
    "\n",
    "print(\"\\nJSON 和 CSV 读写测试完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef1b29",
   "metadata": {},
   "source": [
    "## Test for Matrix computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647e1e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 内核函数测试 ---\n",
      "度矩阵 (前5x5):\n",
      "[[16.  0.  0.  0.  0.]\n",
      " [ 0.  9.  0.  0.  0.]\n",
      " [ 0.  0. 10.  0.  0.]\n",
      " [ 0.  0.  0.  6.  0.]\n",
      " [ 0.  0.  0.  0.  3.]]\n",
      "\n",
      "拉普拉斯矩阵 (前5x5):\n",
      "[[42. -4. -5. -3. -3.]\n",
      " [-4. 29. -6. -3.  0.]\n",
      " [-5. -6. 33. -3.  0.]\n",
      " [-3. -3. -3. 18.  0.]\n",
      " [-3.  0.  0.  0.  8.]]\n",
      "\n",
      "对称归一化拉普拉斯矩阵 (前5x5):\n",
      "[[ 0.9375     -0.08333334 -0.07905694 -0.10206207 -0.14433756]\n",
      " [-0.08333334  0.8888889  -0.10540926 -0.13608277  0.        ]\n",
      " [-0.07905694 -0.10540926  0.9        -0.12909944  0.        ]\n",
      " [-0.10206207 -0.13608277 -0.12909944  0.8333334   0.        ]\n",
      " [-0.14433756  0.          0.          0.          0.6666667 ]]\n"
     ]
    }
   ],
   "source": [
    "# --- 内核函数测试 ---\n",
    "from kernels import degree_matrix, laplacian_matrix, normalized_laplacian_sym\n",
    "\n",
    "# 使用之前从 karate_club_graph 创建的 jax_g 对象\n",
    "# 如果 jax_g 不存在，请先运行前面的单元格\n",
    "print(\"--- 内核函数测试 ---\")\n",
    "\n",
    "# 1. 测试度矩阵\n",
    "deg_matrix = degree_matrix(jax_g)\n",
    "print(\"度矩阵 (前5x5):\")\n",
    "print(deg_matrix[:5, :5])\n",
    "\n",
    "# 2. 测试拉普拉斯矩阵\n",
    "lap_matrix = laplacian_matrix(jax_g)\n",
    "print(\"\\n拉普拉斯矩阵 (前5x5):\")\n",
    "print(lap_matrix[:5, :5])\n",
    "\n",
    "# 3. 测试对称归一化拉普拉斯矩阵\n",
    "norm_lap_sym = normalized_laplacian_sym(jax_g)\n",
    "print(\"\\n对称归一化拉普拉斯矩阵 (前5x5):\")\n",
    "print(norm_lap_sym[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079cd565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 内核函数验证 (与 NetworkX 对比) ---\n",
      "\n",
      "--- 1. 验证度矩阵 ---\n",
      "NetworkX 度矩阵 (前5x5):\n",
      " [[16  0  0  0  0]\n",
      " [ 0  9  0  0  0]\n",
      " [ 0  0 10  0  0]\n",
      " [ 0  0  0  6  0]\n",
      " [ 0  0  0  0  3]]\n",
      "\n",
      "我们的 度矩阵 (前5x5):\n",
      " [[16.  0.  0.  0.  0.]\n",
      " [ 0.  9.  0.  0.  0.]\n",
      " [ 0.  0. 10.  0.  0.]\n",
      " [ 0.  0.  0.  6.  0.]\n",
      " [ 0.  0.  0.  0.  3.]]\n",
      "\n",
      "--> 度矩阵是否与 NetworkX 一致: True\n",
      "\n",
      "----------------------------------------\n",
      "--- 2. 验证拉普拉斯矩阵 ---\n",
      "NetworkX 拉普拉斯矩阵 (前5x5):\n",
      " [[42 -4 -5 -3 -3]\n",
      " [-4 29 -6 -3  0]\n",
      " [-5 -6 33 -3  0]\n",
      " [-3 -3 -3 18  0]\n",
      " [-3  0  0  0  8]]\n",
      "\n",
      "我们的 拉普拉斯矩阵 (前5x5):\n",
      " [[42. -4. -5. -3. -3.]\n",
      " [-4. 29. -6. -3.  0.]\n",
      " [-5. -6. 33. -3.  0.]\n",
      " [-3. -3. -3. 18.  0.]\n",
      " [-3.  0.  0.  0.  8.]]\n",
      "\n",
      "--> 拉普拉斯矩阵是否与 NetworkX 一致: True\n",
      "\n",
      "----------------------------------------\n",
      "--- 3. 验证对称归一化拉普拉斯矩阵 ---\n",
      "NetworkX 归一化拉普拉斯矩阵 (前5x5):\n",
      " [[ 1.         -0.11461365 -0.13430383 -0.10910895 -0.16366342]\n",
      " [-0.11461365  1.         -0.19395246 -0.13130643  0.        ]\n",
      " [-0.13430383 -0.19395246  1.         -0.12309149  0.        ]\n",
      " [-0.10910895 -0.13130643 -0.12309149  1.          0.        ]\n",
      " [-0.16366342  0.          0.          0.          1.        ]]\n",
      "\n",
      "我们的 归一化拉普拉斯矩阵 (前5x5):\n",
      " [[ 1.         -0.08333334 -0.07905694 -0.10206207 -0.14433756]\n",
      " [-0.08333334  1.         -0.10540926 -0.13608277  0.        ]\n",
      " [-0.07905694 -0.10540926  1.         -0.12909944  0.        ]\n",
      " [-0.10206207 -0.13608277 -0.12909944  1.          0.        ]\n",
      " [-0.14433756  0.          0.          0.          1.        ]]\n",
      "\n",
      "--> 对称归一化拉普拉斯矩阵是否与 NetworkX 一致: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 内核函数验证 (与 NetworkX 对比) ---\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from kernels import degree_matrix, laplacian_matrix, normalized_laplacian_sym\n",
    "\n",
    "# 确保 nx_g 和 jax_g 变量存在\n",
    "print(\"--- 内核函数验证 (与 NetworkX 对比) ---\\n\")\n",
    "\n",
    "# 1. 验证度矩阵\n",
    "print(\"--- 1. 验证度矩阵 ---\")\n",
    "# NetworkX 计算方式:\n",
    "nx_degrees = np.array([d for n, d in nx.degree(nx_g)])\n",
    "nx_deg_matrix = np.diag(nx_degrees)\n",
    "# 我们的计算方式:\n",
    "jax_deg_matrix = degree_matrix(jax_g)\n",
    "\n",
    "print(\"NetworkX 度矩阵 (前5x5):\\n\", nx_deg_matrix[:5, :5])\n",
    "print(\"\\n我们的 度矩阵 (前5x5):\\n\", np.asarray(jax_deg_matrix)[:5, :5])\n",
    "print(f\"\\n--> 度矩阵是否与 NetworkX 一致: {np.allclose(nx_deg_matrix, jax_deg_matrix)}\\n\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# 2. 验证拉普拉斯矩阵\n",
    "print(\"--- 2. 验证拉普拉斯矩阵 ---\")\n",
    "# NetworkX 计算方式:\n",
    "nx_lap_matrix = nx.laplacian_matrix(nx_g).toarray()\n",
    "# 我们的计算方式:\n",
    "jax_lap_matrix = laplacian_matrix(jax_g)\n",
    "\n",
    "print(\"NetworkX 拉普拉斯矩阵 (前5x5):\\n\", nx_lap_matrix[:5, :5])\n",
    "print(\"\\n我们的 拉普拉斯矩阵 (前5x5):\\n\", np.asarray(jax_lap_matrix)[:5, :5])\n",
    "print(f\"\\n--> 拉普拉斯矩阵是否与 NetworkX 一致: {np.allclose(nx_lap_matrix, jax_lap_matrix)}\\n\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# 3. 验证对称归一化拉普拉斯矩阵\n",
    "print(\"--- 3. 验证对称归一化拉普拉斯矩阵 ---\")\n",
    "# NetworkX 计算方式:\n",
    "nx_norm_lap_matrix = nx.normalized_laplacian_matrix(nx_g).toarray()\n",
    "# 我们的计算方式 (注意：为了与 networkx 标准行为对齐，需设置 add_self_loops=False)\n",
    "jax_norm_lap_matrix = normalized_laplacian_sym(jax_g, add_self_loops=False)\n",
    "\n",
    "print(\"NetworkX 归一化拉普拉斯矩阵 (前5x5):\\n\", nx_norm_lap_matrix[:5, :5])\n",
    "print(\"\\n我们的 归一化拉普拉斯矩阵 (前5x5):\\n\", np.asarray(jax_norm_lap_matrix)[:5, :5])\n",
    "print(f\"\\n--> 对称归一化拉普拉斯矩阵是否与 NetworkX 一致: {np.allclose(nx_norm_lap_matrix, jax_norm_lap_matrix)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在生成一个包含 2500 个节点和大约 10000 条边的 Barabasi-Albert 图...\n",
      "NetworkX 图已生成.\n",
      "节点数: 2500, 边数: 9984\n",
      "JAX Graph 对象已创建.\n",
      "\n",
      "--- 高级内核与性能测试 ---\n",
      "\n",
      "--- 1. 验证随机游走归一化拉普拉斯矩阵 ---\n",
      "NumPy/NetworkX 结果 (前5x5):\n",
      " [[ 1.         -0.00515464 -0.00515464 -0.00515464 -0.00515464]\n",
      " [-0.01587302  1.          0.          0.          0.        ]\n",
      " [-0.03030303  0.          1.          0.          0.        ]\n",
      " [-0.01612903  0.          0.          1.          0.        ]\n",
      " [-0.03333333  0.          0.          0.          1.        ]]\n",
      "\n",
      "JAX 结果 (前5x5):\n",
      " [[ 1.         -0.00515464 -0.00515464 -0.00515464 -0.00515464]\n",
      " [-0.01587302  1.          0.          0.          0.        ]\n",
      " [-0.03030303  0.          1.          0.          0.        ]\n",
      " [-0.01612903  0.          0.          1.          0.        ]\n",
      " [-0.03333334  0.          0.          0.          1.        ]]\n",
      "\n",
      "结果是否一致: True\n",
      "JAX 实现速度: 5.310564s\n",
      "NumPy 实现速度: 41.733778s\n",
      "----------------------------------------\n",
      "--- 2. 验证拉普拉斯特征分解 ---\n",
      "NumPy/SciPy 特征值 (基于我们的L_sym):\n",
      " [-3.34413108e-09  3.58761184e-01  3.60215315e-01  3.61980818e-01\n",
      "  3.64182462e-01]\n",
      "\n",
      "JAX 特征值:\n",
      " [-3.34413423e-09  3.58761184e-01  3.60215315e-01  3.61980818e-01\n",
      "  3.64182462e-01]\n",
      "\n",
      "NumPy/SciPy 特征向量 (前5行, 基于我们的L_sym):\n",
      " [[ 0.09856746  0.01470988 -0.00137076  0.01025764 -0.0155561 ]\n",
      " [ 0.05616981  0.01869102  0.00432624  0.05402572  0.01366207]\n",
      " [ 0.04065273 -0.01841415 -0.01550813 -0.00912158  0.01638134]\n",
      " [ 0.05572224 -0.02988395  0.0175404  -0.01325599  0.02116836]\n",
      " [ 0.03876085 -0.00794953  0.01334634 -0.02344129 -0.01688468]]\n",
      "\n",
      "JAX 特征向量 (前5行):\n",
      " [[ 0.09856746  0.01470988 -0.00137076  0.01025764 -0.0155561 ]\n",
      " [ 0.05616981  0.01869102  0.00432624  0.05402572  0.01366207]\n",
      " [ 0.04065273 -0.01841415 -0.01550813 -0.00912158  0.01638134]\n",
      " [ 0.05572224 -0.02988395  0.0175404  -0.01325599  0.02116836]\n",
      " [ 0.03876085 -0.00794953  0.01334634 -0.02344129 -0.01688468]]\n",
      "\n",
      "特征值是否一致 (atol=1e-5): True\n",
      "特征向量是否一致 (atol=1e-5): True\n",
      "\n",
      "JAX 实现速度 (k=5): 9.922291s\n",
      "NumPy 实现速度: 12.622458s\n",
      "----------------------------------------\n",
      "--- 3. 验证 SpGEMM (消息传递) ---\n",
      "\\n--- 测试常规 SpGEMM ---\n",
      "常规 SpGEMM 实现速度: 0.041871s\n",
      "\\n--- 测试并行 SpGEMM (pmap) on 8 devices ---\n",
      "结果是否一致: True\n",
      "并行 SpGEMM (pmap) 实现速度: 0.212933s\n",
      "加速比: 0.20x\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 这个标志告诉 JAX/XLA 在 CPU 上创建指定数量的“虚拟”设备。\n",
    "# 将 '8' 替换为您希望使用的CPU核心数。\n",
    "# 注意：这个单元格必须在任何 jax 导入之前运行。\n",
    "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=8' \n",
    "\n",
    "# --- 高级内核与性能测试 ---\n",
    "import timeit\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import jax\n",
    "from graphs import from_networkx, Graph\n",
    "import jax.numpy as jnp\n",
    "from kernels import (\n",
    "    random_walk_normalized_laplacian, \n",
    "    laplacian_eigensystem,\n",
    "    spgemm,\n",
    "    normalized_laplacian_sym\n",
    ")\n",
    "\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# more heavy duty\n",
    "# 使用 Barabasi-Albert 模型生成一个规模更大的图\n",
    "n_nodes = 2500  # 节点数\n",
    "m_edges = 4      # 每个新节点连接到的现有节点数\n",
    "print(f\"正在生成一个包含 {n_nodes} 个节点和大约 {n_nodes * m_edges} 条边的 Barabasi-Albert 图...\")\n",
    "\n",
    "# 1. 创建 NetworkX 图对象\n",
    "nx_g = nx.barabasi_albert_graph(n=n_nodes, m=m_edges, seed=42)\n",
    "print(\"NetworkX 图已生成.\")\n",
    "print(f\"节点数: {nx_g.number_of_nodes()}, 边数: {nx_g.number_of_edges()}\")\n",
    "\n",
    "\n",
    "# 2. 将 NetworkX 图转换为我们的 JAX Graph 对象\n",
    "# 假设 Graph.from_networkx 是正确的转换函数\n",
    "jax_g = from_networkx(nx_g)\n",
    "print(\"JAX Graph 对象已创建.\\n\")\n",
    "\n",
    "\n",
    "print(\"--- 高级内核与性能测试 ---\\n\")\n",
    "\n",
    "# --- 1. 随机游走归一化拉普拉斯矩阵 ---\n",
    "print(\"--- 1. 验证随机游走归一化拉普拉斯矩阵 ---\")\n",
    "\n",
    "# NetworkX/NumPy 计算方式\n",
    "def lrw_numpy(A):\n",
    "    D = np.diag(np.sum(A, axis=1))\n",
    "    # 防止除以零\n",
    "    D_inv = np.linalg.inv(D)\n",
    "    return np.eye(A.shape[0]) - D_inv @ A\n",
    "\n",
    "A_nx = nx.to_numpy_array(nx_g)\n",
    "lrw_nx_result = lrw_numpy(A_nx)\n",
    "\n",
    "# 我们的计算方式\n",
    "# 注意：为了与 networkx 标准行为对齐，需设置 add_self_loops=False\n",
    "lrw_jax_result = random_walk_normalized_laplacian(jax_g, add_self_loops=False)\n",
    "\n",
    "print(\"NumPy/NetworkX 结果 (前5x5):\\n\", lrw_nx_result[:5, :5])\n",
    "print(\"\\nJAX 结果 (前5x5):\\n\", lrw_jax_result[:5, :5])\n",
    "print(f\"\\n结果是否一致: {np.allclose(lrw_nx_result, lrw_jax_result)}\")\n",
    "\n",
    "# 性能比较 (不含编译时间)\n",
    "# 预热：先运行一次 JAX 函数以完成 JIT 编译\n",
    "lrw_jax_result.block_until_ready() \n",
    "\n",
    "jax_time = timeit.timeit(lambda: random_walk_normalized_laplacian(jax_g, add_self_loops=False).block_until_ready(), number=100)\n",
    "numpy_time = timeit.timeit(lambda: lrw_numpy(A_nx), number=100)\n",
    "\n",
    "print(f\"JAX 实现速度: {jax_time:.6f}s\")\n",
    "print(f\"NumPy 实现速度: {numpy_time:.6f}s\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 2. 拉普拉斯特征分解 ---\n",
    "print(\"--- 2. 验证拉普拉斯特征分解 ---\")\n",
    "k = 5 # 计算前 5 个特征值/向量\n",
    "\n",
    "# 1. 首先用我们的函数计算对称归一化拉普拉斯矩阵\n",
    "l_sym_jax = normalized_laplacian_sym(jax_g, add_self_loops=False, use_weights=False)\n",
    "\n",
    "# 2. 然后对这个矩阵进行标准的 NumPy/SciPy 特征分解\n",
    "# 确保 jax_enable_x64=True，这样 np.linalg.eigh 和我们的函数都在 float64 上操作\n",
    "vals_ref, vecs_ref = np.linalg.eigh(np.asarray(l_sym_jax))\n",
    "vals_ref, vecs_ref = vals_ref[:k], vecs_ref[:, :k]\n",
    "\n",
    "# 3. 调用我们自己的 laplacian_eigensystem 函数\n",
    "# 强制使用 float64 以便与 NumPy 的 eigh 进行精确比较\n",
    "vals_jax, vecs_jax = laplacian_eigensystem(jax_g, k=k, use_weights=False, force_float64=True)\n",
    "\n",
    "print(\"NumPy/SciPy 特征值 (基于我们的L_sym):\\n\", vals_ref)\n",
    "print(\"\\nJAX 特征值:\\n\", vals_jax)\n",
    "print(\"\\nNumPy/SciPy 特征向量 (前5行, 基于我们的L_sym):\\n\", vecs_ref[:5, :])\n",
    "print(\"\\nJAX 特征向量 (前5行):\\n\", vecs_jax[:5, :])\n",
    "\n",
    "# 特征向量的符号可能不一致，但方向应一致，故比较绝对值\n",
    "print(f\"\\n特征值是否一致 (atol=1e-5): {np.allclose(vals_ref, vals_jax, atol=1e-5)}\")\n",
    "print(f\"特征向量是否一致 (atol=1e-5): {np.allclose(np.abs(vecs_ref), np.abs(vecs_jax), atol=1e-5)}\")\n",
    "\n",
    "# 性能比较\n",
    "# 预热\n",
    "vals_jax.block_until_ready()\n",
    "vecs_jax.block_until_ready()\n",
    "\n",
    "# 修正: 定义 NumPy 的基准矩阵 L_sym_nx，确保它对应的是大的 Barabasi-Albert 图\n",
    "# 注意：这里我们使用 NumPy 的原生方式来计算，以进行公平的速度比较\n",
    "# 而不是使用我们之前计算的 l_sym_jax，因为那会包含 JAX -> NumPy 的转换开销\n",
    "A_nx = nx.to_numpy_array(nx_g)\n",
    "L_sym_nx = nx.normalized_laplacian_matrix(nx_g).toarray()\n",
    "\n",
    "\n",
    "jax_time = timeit.timeit(lambda: laplacian_eigensystem(jax_g, k=k, force_float64=True)[0].block_until_ready(), number=10)\n",
    "numpy_time = timeit.timeit(lambda: np.linalg.eigh(L_sym_nx), number=10)\n",
    "\n",
    "print(f\"\\nJAX 实现速度 (k={k}): {jax_time:.6f}s\")\n",
    "print(f\"NumPy 实现速度: {numpy_time:.6f}s\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f755f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在生成一个包含 10000 个节点和大约 1000000 条边的 Barabasi-Albert 图...\n",
      "NetworkX 图已生成.\n",
      "节点数: 10000, 边数: 990000\n",
      "JAX Graph 对象已创建.\n",
      "\n",
      "--- 验证 SpGEMM ---\n",
      "特征维度 = 128\n",
      "\n",
      "--- Scipy基准 ---\n",
      "SciPy SpGEMM: 0.391695s\n",
      "\n",
      "--- 测试单线程 JAX SpGEMM ---\n",
      "JAX SpGEMM速度: 1.767550s\n",
      "JAX 结果是否与 SciPy 一致: True\n",
      "\n",
      "--- 测试并行 SpGEMM (pmap) on 8 devices ---\n",
      "结果是否一致: True\n",
      "并行 SpGEMM (pmap) 实现速度: 1.138581s\n",
      "加速比: 1.55x\n",
      "JAX 结果是否与 SciPy 一致: True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 这个标志告诉 JAX/XLA 在 CPU 上创建指定数量的“虚拟”设备。\n",
    "# 注意：这个单元格必须在任何 jax 导入之前运行。\n",
    "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=8' \n",
    "\n",
    "# --- 高级内核与性能测试 ---\n",
    "import timeit\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import jax\n",
    "from graphs import from_networkx, Graph\n",
    "import jax.numpy as jnp\n",
    "from kernels import (\n",
    "    random_walk_normalized_laplacian, \n",
    "    laplacian_eigensystem,\n",
    "    spgemm,\n",
    "    normalized_laplacian_sym\n",
    ")\n",
    "\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# more heavy duty\n",
    "# 使用 Barabasi-Albert 模型生成一个规模更大的图\n",
    "n_nodes = 10000  # 节点数\n",
    "m_edges = 100      # 每个新节点连接到的现有节点数\n",
    "print(f\"正在生成一个包含 {n_nodes} 个节点和大约 {n_nodes * m_edges} 条边的 Barabasi-Albert 图...\")\n",
    "\n",
    "# 1. 创建 NetworkX 图对象\n",
    "nx_g = nx.barabasi_albert_graph(n=n_nodes, m=m_edges, seed=42)\n",
    "print(\"NetworkX 图已生成.\")\n",
    "print(f\"节点数: {nx_g.number_of_nodes()}, 边数: {nx_g.number_of_edges()}\")\n",
    "\n",
    "# 2. 将 NetworkX 图转换为我们的 JAX Graph 对象\n",
    "jax_g = from_networkx(nx_g)\n",
    "print(\"JAX Graph 对象已创建.\\n\")\n",
    "\n",
    "# --- 3. SpGEMM (消息传递) ---\n",
    "print(\"--- 验证 SpGEMM ---\")\n",
    "# 创建一个随机的节点特征矩阵\n",
    "key = jax.random.PRNGKey(42)\n",
    "# 使用一个能被CPU核心数整除的特征维度，例如 128\n",
    "n_features = 128\n",
    "print(f\"特征维度 = {n_features}\")\n",
    "features = jax.random.normal(key, (jax_g.n_nodes, n_features)) \n",
    "\n",
    "# --- NetworkX/SciPy SpGEMM (作为基准) ---\n",
    "print(\"\\n--- Scipy基准 ---\")\n",
    "import scipy.sparse\n",
    "# 将 networkx 图转换为稀疏的 SciPy 矩阵\n",
    "A_scipy = nx.to_scipy_sparse_array(nx_g, dtype=np.float32)\n",
    "# 将 JAX 特征数组转换为 NumPy 数组\n",
    "features_np = np.asarray(features)\n",
    "# 预热\n",
    "scipy_result = A_scipy @ features_np\n",
    "# 性能比较\n",
    "scipy_time = timeit.timeit(lambda: A_scipy @ features_np, number=10)\n",
    "print(f\"SciPy SpGEMM: {scipy_time:.6f}s\")\n",
    "\n",
    "# --- 常规 SpGEMM ---\n",
    "print(\"\\n--- 测试单线程 JAX SpGEMM ---\")\n",
    "# 我们的计算方式\n",
    "spgemm_jax_result = spgemm(jax_g, features)\n",
    "# 预热\n",
    "spgemm_jax_result.block_until_ready()\n",
    "# 性能比较\n",
    "jax_time = timeit.timeit(lambda: spgemm(jax_g, features).block_until_ready(), number=10)\n",
    "print(f\"JAX SpGEMM速度: {jax_time:.6f}s\")\n",
    "\n",
    "print(f\"JAX 结果是否与 SciPy 一致: {np.allclose(spgemm_jax_result, scipy_result, atol=1e-5)}\")\n",
    "\n",
    "# --- 并行 SpGEMM (pmap) ---\n",
    "# 仅在有多个设备时运行\n",
    "if jax.local_device_count() > 1:\n",
    "    print(f\"\\n--- 测试并行 SpGEMM (pmap) on {jax.local_device_count()} devices ---\")\n",
    "    from kernels import spgemm_pmap # 导入 pmap 版本\n",
    "    \n",
    "    # 执行 pmap 版本的 spgemm\n",
    "    spgemm_pmap_result = spgemm_pmap(jax_g, features)\n",
    "    \n",
    "    # 验证结果是否一致\n",
    "    print(f\"结果是否一致: {np.allclose(spgemm_jax_result, spgemm_pmap_result, atol=1e-5)}\")\n",
    "\n",
    "    # 性能比较\n",
    "    # 预热\n",
    "    spgemm_pmap_result.block_until_ready()\n",
    "    pmap_time = timeit.timeit(lambda: spgemm_pmap(jax_g, features).block_until_ready(), number=10)\n",
    "    \n",
    "    print(f\"并行 SpGEMM (pmap) 实现速度: {pmap_time:.6f}s\")\n",
    "    print(f\"加速比: {jax_time / pmap_time:.2f}x\")\n",
    "    print(f\"JAX 结果是否与 SciPy 一致: {np.allclose(spgemm_pmap_result, scipy_result, atol=1e-5)}\")\n",
    "else:\n",
    "    print(\"\\n--- 跳过 pmap 测试 (仅检测到单个设备) ---\")\n",
    "\n",
    "print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
